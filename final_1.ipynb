{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ydwo1jsKfcH"
   },
   "source": [
    "# Bi-Directional Attention Flow (BiDAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "3MHQ7Mk2KfcQ",
    "outputId": "c9a3e0a3-519b-4946-eb22-05e59303f813"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "#import spacy\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "#import jsonlines\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Conv1D,Dense, Activation, Multiply, Add, Lambda,Conv2D ,Conv3D, \\\n",
    "MaxPooling1D,MaxPooling2D,Input, TimeDistributed, LSTM, Bidirectional,Flatten,Embedding,Dense,Dropout,Concatenate,AveragePooling1D\n",
    "from keras.initializers import Constant\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adadelta,Adam\n",
    "import tensorflow as tf\n",
    "from keras.activations import linear\n",
    "from keras.layers.advanced_activations import Softmax\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "GKaGaCKAKr7F",
    "outputId": "239e358e-efc6-4dd0-d1db-1ea6d31dffda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kas4mezKfdR"
   },
   "outputs": [],
   "source": [
    "''' The Highway is used to form a  residual connection where T-transform_gate go to sigmoid Activation 1-T is carry gate\n",
    "Z=T g(W y+b) + (1-T) y  '''\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Dense, Activation, Multiply, Add, Lambda\n",
    "from keras.initializers import Constant\n",
    "\n",
    "\n",
    "class Highway(Layer):\n",
    "\n",
    "    activation = None\n",
    "    transform_gate_bias = None\n",
    "\n",
    "    def __init__(self, activation='relu', transform_gate_bias=-1, **kwargs):\n",
    "        self.activation = activation\n",
    "        self.transform_gate_bias = transform_gate_bias\n",
    "        super(Highway, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        dim = input_shape[-1]\n",
    "        transform_gate_bias_initializer = Constant(self.transform_gate_bias)\n",
    "        input_shape_dense_1 = input_shape[-1]\n",
    "        self.dense_1 = Dense(units=dim, bias_initializer=transform_gate_bias_initializer)\n",
    "        self.dense_1.build(input_shape)\n",
    "        self.dense_2 = Dense(units=dim)\n",
    "        self.dense_2.build(input_shape)\n",
    "        self.trainable_weights = self.dense_1.trainable_weights + self.dense_2.trainable_weights\n",
    "\n",
    "        super(Highway, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        dim = K.int_shape(x)[-1]\n",
    "        transform_gate = self.dense_1(x)\n",
    "        transform_gate = Activation(\"sigmoid\")(transform_gate)\n",
    "        carry_gate = Lambda(lambda x: 1.0 - x, output_shape=(dim,))(transform_gate)\n",
    "        transformed_data = self.dense_2(x)\n",
    "        transformed_data = Activation(self.activation)(transformed_data)\n",
    "        transformed_gated = Multiply()([transform_gate, transformed_data])\n",
    "        identity_gated = Multiply()([carry_gate, x])\n",
    "        value = Add()([transformed_gated, identity_gated])\n",
    "        return value\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['activation'] = self.activation\n",
    "        config['transform_gate_bias'] = self.transform_gate_bias\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLG_jxHpKfda"
   },
   "outputs": [],
   "source": [
    "''' calculating the Similarity between the query and the contex concatenation of both  query , contex vector and \n",
    "pairwise Similarity between query and contex '''\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "tf.compat.v1.keras.backend.expand_dims\n",
    "\n",
    "class Similarity(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Similarity, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_similarity(self, repeated_context_vectors, repeated_query_vectors):\n",
    "        element_wise_multiply = repeated_context_vectors * repeated_query_vectors\n",
    "        concatenated_tensor = K.concatenate(\n",
    "            [repeated_context_vectors, repeated_query_vectors, element_wise_multiply], axis=-1)\n",
    "        dot_product = K.squeeze(K.dot(concatenated_tensor, self.kernel), axis=-1)\n",
    "        return linear(dot_product + self.bias)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        word_vector_dim = input_shape[0][-1]\n",
    "        weight_vector_dim = word_vector_dim * 3\n",
    "        self.kernel = self.add_weight(name='similarity_weight',\n",
    "                                      shape=(weight_vector_dim, 1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(name='similarity_bias',\n",
    "                                    shape=(),\n",
    "                                    initializer='ones',\n",
    "                                    trainable=True)\n",
    "        super(Similarity, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        context_vectors, query_vectors = inputs\n",
    "        num_context_words = K.shape(context_vectors)[1]\n",
    "        num_query_words = K.shape(query_vectors)[1]\n",
    "        context_dim_repeat = K.concatenate([[1, 1], [num_query_words], [1]], 0)\n",
    "        query_dim_repeat = K.concatenate([[1], [num_context_words], [1, 1]], 0)\n",
    "        repeated_context_vectors = K.tile(tf.compat.v1.keras.backend.expand_dims(context_vectors, axis=2), context_dim_repeat)\n",
    "        repeated_query_vectors = K.tile(tf.compat.v1.keras.backend.expand_dims(query_vectors, axis=1), query_dim_repeat)\n",
    "        similarity_matrix = self.compute_similarity(repeated_context_vectors, repeated_query_vectors)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch_size = input_shape[0][0]\n",
    "        num_context_words = input_shape[0][1]\n",
    "        num_query_words = input_shape[1][1]\n",
    "        return (batch_size, num_context_words, num_query_words)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4nXYU-NKfdi"
   },
   "outputs": [],
   "source": [
    "'''Context-to-Query Attention taking the row-wise softmax of Similarity and multiply with question vector'''\n",
    "\n",
    "class C2QAttention(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(C2QAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(C2QAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        similarity_matrix, encoded_question = inputs\n",
    "        context_to_query_attention = Softmax(axis=-1)(similarity_matrix)\n",
    "        encoded_question = K.expand_dims(encoded_question, axis=1)\n",
    "        return K.sum(K.expand_dims(context_to_query_attention, axis=-1) * encoded_question, -2)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        similarity_matrix_shape, encoded_question_shape = input_shape\n",
    "        return similarity_matrix_shape[:-1] + encoded_question_shape[-1:]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzrQBKheKfdr"
   },
   "outputs": [],
   "source": [
    "'''Query-to-Context (Q2C) Attention we taking the max in row-wise of similarity_matrix and applying softmax at last\n",
    "multiply with contex vector '''\n",
    "class Q2CAttention(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Q2CAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Q2CAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        similarity_matrix, encoded_context = inputs\n",
    "        max_similarity = K.max(similarity_matrix, axis=-1)\n",
    "        # by default, axis = -1 in Softmax\n",
    "        context_to_query_attention = Softmax()(max_similarity)\n",
    "        weighted_sum = K.sum(K.expand_dims(context_to_query_attention, axis=-1) * encoded_context, -2)\n",
    "        expanded_weighted_sum = K.expand_dims(weighted_sum, 1)\n",
    "        num_of_repeatations = K.shape(encoded_context)[1]\n",
    "        return K.tile(expanded_weighted_sum, [1, num_of_repeatations, 1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        similarity_matrix_shape, encoded_context_shape = input_shape\n",
    "        return similarity_matrix_shape[:-1] + encoded_context_shape[-1:]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fWVxJUxKfdz"
   },
   "outputs": [],
   "source": [
    "'''MergedContext multiply the contex vector with Context-to-Query and Query-to-Context vectors at last concatenated \n",
    "contex,context_to_query,multiply1,multiply2'''\n",
    "\n",
    "class MergedContext(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MergedContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(MergedContext, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        encoded_context, context_to_query_attention, query_to_context_attention = inputs\n",
    "        element_wise_multiply1 = encoded_context * context_to_query_attention\n",
    "        element_wise_multiply2 = encoded_context * query_to_context_attention\n",
    "        concatenated_tensor = K.concatenate(\n",
    "            [encoded_context, context_to_query_attention, element_wise_multiply1, element_wise_multiply2], axis=-1)\n",
    "        return concatenated_tensor\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        encoded_context_shape, _, _ = input_shape\n",
    "        return encoded_context_shape[:-1] + (encoded_context_shape[-1] * 4, )\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErcobPNdKfeM"
   },
   "outputs": [],
   "source": [
    "'''CombineOutputs use to stack the inputs'''\n",
    "class CombineOutputs(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CombineOutputs, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(CombineOutputs, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        span_begin_probabilities, span_end_probabilities,span_begin_probabilities_1,span_end_probabilities_1,span_end_probabilities_2 = inputs\n",
    "        return K.stack([span_begin_probabilities, span_end_probabilities,span_begin_probabilities_1,span_end_probabilities_1,span_end_probabilities_2 ], axis = 1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        number_of_tensors = len(input_shape)\n",
    "        return input_shape[0][0:1] + (number_of_tensors, ) + input_shape[0][1:]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIJ7QdmaKfej"
   },
   "outputs": [],
   "source": [
    "'''MagnitudeVectors use to Loading the glove vector '''\n",
    "import os\n",
    "from pymagnitude import Magnitude, MagnitudeUtils\n",
    "\n",
    "\n",
    "class MagnitudeVectors():\n",
    "\n",
    "    def __init__(self, emdim):\n",
    "\n",
    "        base_dir = \"challenge\"\n",
    "\n",
    "        self.fasttext_dim = 300\n",
    "        self.glove_dim = emdim - 300\n",
    "\n",
    "        assert self.glove_dim in [50, 100, 200,\n",
    "                                  300], \"Embedding dimension must be one of the following: 350, 400, 500, 600\"\n",
    "\n",
    "        print(\"Will download magnitude files from the server if they aren't avaialble locally.. So, grab a cup of coffee while the downloading is under progress..\")\n",
    "        glove = Magnitude(MagnitudeUtils.download_model('glove/medium/glove.6B.{}d'.format(self.glove_dim),\n",
    "                                                        download_dir=os.path.join(base_dir, 'magnitude')), case_insensitive=True)\n",
    "        fasttext = Magnitude(MagnitudeUtils.download_model('fasttext/medium/wiki-news-300d-1M-subword',\n",
    "                                                           download_dir=os.path.join(base_dir, 'magnitude')), case_insensitive=True)\n",
    "        self.vectors = Magnitude(glove, fasttext)\n",
    "\n",
    "    def load_vectors(self):\n",
    "        return self.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VldyRlqxKfey"
   },
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "\n",
    "class ModelMGPU(Model):\n",
    "    def __init__(self, ser_model, gpus=None):\n",
    "        pmodel = multi_gpu_model(ser_model, gpus)\n",
    "        self.__dict__.update(pmodel.__dict__)\n",
    "        self._smodel = ser_model\n",
    "\n",
    "    def __getattribute__(self, attrname):\n",
    "        '''Override load and save methods to be used from the serial-model. The\n",
    "        serial-model holds references to the weights in the multi-gpu model.\n",
    "        '''\n",
    "        # return Model.__getattribute__(self, attrname)\n",
    "        if 'load' in attrname or 'save' in attrname:\n",
    "            return getattr(self._smodel, attrname)\n",
    "\n",
    "        return super(ModelMGPU, self).__getattribute__(attrname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adadelta,Adam\n",
    "from scipy.sparse import hstack\n",
    "from time import time\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "class BidirectionalAttentionFlow():\n",
    "\n",
    "    def __init__(self, emdim, max_passage_length=None, max_query_length=None, num_highway_layers=2, num_decoders=1,\n",
    "                 encoder_dropout=0, decoder_dropout=0):\n",
    "        self.emdim = emdim\n",
    "        self.max_passage_length =250\n",
    "        self.max_query_length = 35\n",
    "\n",
    "        passage_input = Input(shape=(self.max_passage_length, emdim), dtype='float32', name=\"passage_input\")\n",
    "        question_input = Input(shape=(self.max_query_length, emdim), dtype='float32', name=\"question_input\")\n",
    "\n",
    "        choice_input_1 = Input(shape=(8, emdim), dtype='float32', name=\"choice_input_1\")\n",
    "        choice_input_2 = Input(shape=(8, emdim), dtype='float32', name=\"choice_input_2\")\n",
    "        choice_input_3 = Input(shape=(8, emdim), dtype='float32', name=\"choice_input_3\")\n",
    "        choice_input_4 = Input(shape=(8, emdim), dtype='float32', name=\"choice_input_4\")\n",
    "        choice_input_5 = Input(shape=(8, emdim), dtype='float32', name=\"choice_input_5\")\n",
    "\n",
    "        question_embedding = question_input\n",
    "        passage_embedding = passage_input\n",
    "        #choice_embedding = choice_input\n",
    "        for i in range(num_highway_layers):\n",
    "            highway_layer = Highway(name='highway_{}'.format(i))\n",
    "            question_layer = TimeDistributed(highway_layer, name=highway_layer.name + \"_qtd\")\n",
    "            question_embedding = question_layer(question_embedding)\n",
    "            passage_layer = TimeDistributed(highway_layer, name=highway_layer.name + \"_ptd\")\n",
    "            passage_embedding = passage_layer(passage_embedding)\n",
    "           \n",
    "\n",
    "        encoder_layer = Bidirectional(LSTM(175, recurrent_dropout=encoder_dropout,\n",
    "                                           return_sequences=True), name='bidirectional_encoder')\n",
    "        encoded_question = encoder_layer(question_embedding)\n",
    "        encoded_passage = encoder_layer(passage_embedding)\n",
    "        \n",
    "\n",
    "        similarity_matrix = Similarity(name='similarity_layer')([encoded_passage, encoded_question])\n",
    "\n",
    "        context_to_query_attention = C2QAttention(name='context_to_query_attention')([\n",
    "            similarity_matrix, encoded_question])\n",
    "        query_to_context_attention = Q2CAttention(name='query_to_context_attention')([\n",
    "            similarity_matrix, encoded_passage])\n",
    "      \n",
    "\n",
    "        merged_context = MergedContext(name='merged_context')(\n",
    "            [encoded_passage, context_to_query_attention, query_to_context_attention])\n",
    "        \n",
    "        modeled_passage = merged_context\n",
    "        \n",
    "        for i in range(num_decoders):\n",
    "            hidden_layer = Bidirectional(LSTM(175, recurrent_dropout=decoder_dropout,\n",
    "                                              return_sequences=True), name='bidirectional_decoder_{}'.format(i))\n",
    "            modeled_passage = hidden_layer(modeled_passage)\n",
    "\n",
    "        similarity_matrix_choice_1 = Similarity(name='similarity_layer_choice_1')([ choice_input_1,modeled_passage])\n",
    "        similarity_matrix_choice_2 = Similarity(name='similarity_layer_choice_2')([ choice_input_2,modeled_passage])\n",
    "        similarity_matrix_choice_3 = Similarity(name='similarity_layer_choice_3')([ choice_input_3,modeled_passage])\n",
    "        similarity_matrix_choice_4 = Similarity(name='similarity_layer_choice_4')([ choice_input_4,modeled_passage])\n",
    "        similarity_matrix_choice_5 = Similarity(name='similarity_layer_choice_5')([ choice_input_5,modeled_passage])\n",
    "\n",
    "\n",
    "        merged_context = CombineOutputs(name='combine_outputs')(\n",
    "            [similarity_matrix_choice_1, similarity_matrix_choice_2, similarity_matrix_choice_3,similarity_matrix_choice_4,similarity_matrix_choice_5])\n",
    "        \n",
    "        modeled_passage = merged_context\n",
    "        \n",
    "        den=Dense(150, activation='relu')( modeled_passage)\n",
    "        dropout_layer3=Dropout(rate=0.5)(den)\n",
    "        den=Dense(70, activation='relu')( dropout_layer3)\n",
    "        dropout_layer3=Dropout(rate=0.5)(den)\n",
    "        \n",
    "        \n",
    "        flat_out=Flatten()(dropout_layer3)\n",
    "        output=Dense(5, activation='softmax')( flat_out )\n",
    "       \n",
    "        \n",
    "        model = Model([passage_input, question_input,choice_input_1,choice_input_2,choice_input_3,choice_input_4,choice_input_5],[output])\n",
    "\n",
    "        model.summary()\n",
    "        \n",
    "\n",
    "        try:\n",
    "            model = ModelMGPU(model)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def load_bidaf(self, path):\n",
    "        custom_objects = {\n",
    "            'Highway': Highway,\n",
    "            'Similarity': Similarity,\n",
    "            'C2QAttention': C2QAttention,\n",
    "            'Q2CAttention': Q2CAttention,\n",
    "            'MergedContext': MergedContext,\n",
    "            'CombineOutputs': CombineOutputs\n",
    "        }\n",
    "\n",
    "        self.model = load_model(path, custom_objects=custom_objects)\n",
    "\n",
    "    def train_model(self, train_generator, steps_per_epoch=None, epochs=1, validation_generator=None,\n",
    "                    validation_steps=None,  use_multiprocessing=False, shuffle=True, initial_epoch=0,\n",
    "                    save_history=False, save_model_per_epoch=True):\n",
    "\n",
    "        saved_items_dir = \"/content/drive/My Drive/case_study1/saved_items\"\n",
    "        if not os.path.exists(saved_items_dir):\n",
    "            os.makedirs(saved_items_dir)\n",
    "\n",
    "        callbacks = []\n",
    "\n",
    "        if save_history:\n",
    "            history_file = os.path.join(saved_items_dir, 'history')\n",
    "            csv_logger = CSVLogger(history_file, append=True)\n",
    "            callbacks.append(csv_logger)\n",
    "\n",
    "        if save_model_per_epoch:\n",
    "            save_model_file = os.path.join(saved_items_dir, 'bidaf_{epoch:02d}.h5')\n",
    "            log_dir=\"saved_items/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "            checkpoint_path = \"saved_items/weights-improvement.hdf5\" \n",
    "            checkpoint = ModelCheckpoint(checkpoint_path, verbose=1)\n",
    "            callbacks_list = [checkpoint,tensorboard_callback]\n",
    "\n",
    "        history = self.model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs,\n",
    "                                           callbacks=callbacks_list, validation_data=validation_generator,\n",
    "                                           validation_steps=validation_steps, \n",
    "                                           use_multiprocessing=use_multiprocessing, shuffle=shuffle,\n",
    "                                           initial_epoch=initial_epoch,class_weight='auto')\n",
    "        if save_model_per_epoch:\n",
    "            self.model.save(os.path.join(saved_items_dir, 'bidaf.h5'))\n",
    "\n",
    "        return history, self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bSN5kNGUKffC",
    "outputId": "69d212b3-c480-47e0-fcbf-47e36dcaee7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "passage_input (InputLayer)      (None, 250, 350)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question_input (InputLayer)     (None, 35, 350)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_0_ptd (TimeDistributed) (None, 250, 350)     245700      passage_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "highway_0_qtd (TimeDistributed) (None, 35, 350)      245700      question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "highway_1_ptd (TimeDistributed) (None, 250, 350)     245700      highway_0_ptd[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "highway_1_qtd (TimeDistributed) (None, 35, 350)      245700      highway_0_qtd[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_encoder (Bidirect multiple             736400      highway_1_qtd[0][0]              \n",
      "                                                                 highway_1_ptd[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer (Similarity)   (None, 250, 35)      1051        bidirectional_encoder[1][0]      \n",
      "                                                                 bidirectional_encoder[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "context_to_query_attention (C2Q (None, 250, 350)     0           similarity_layer[0][0]           \n",
      "                                                                 bidirectional_encoder[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "query_to_context_attention (Q2C (None, 250, 350)     0           similarity_layer[0][0]           \n",
      "                                                                 bidirectional_encoder[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "merged_context (MergedContext)  (None, 250, 1400)    0           bidirectional_encoder[1][0]      \n",
      "                                                                 context_to_query_attention[0][0] \n",
      "                                                                 query_to_context_attention[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_decoder_0 (Bidire (None, 250, 350)     2206400     merged_context[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "choice_input_1 (InputLayer)     (None, 8, 350)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_decoder_1 (Bidire (None, 250, 350)     736400      bidirectional_decoder_0[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "choice_input_2 (InputLayer)     (None, 8, 350)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "choice_input_3 (InputLayer)     (None, 8, 350)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "choice_input_4 (InputLayer)     (None, 8, 350)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "choice_input_5 (InputLayer)     (None, 8, 350)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_choice_1 (Simi (None, 8, 250)       1051        choice_input_1[0][0]             \n",
      "                                                                 bidirectional_decoder_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_choice_2 (Simi (None, 8, 250)       1051        choice_input_2[0][0]             \n",
      "                                                                 bidirectional_decoder_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_choice_3 (Simi (None, 8, 250)       1051        choice_input_3[0][0]             \n",
      "                                                                 bidirectional_decoder_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_choice_4 (Simi (None, 8, 250)       1051        choice_input_4[0][0]             \n",
      "                                                                 bidirectional_decoder_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_choice_5 (Simi (None, 8, 250)       1051        choice_input_5[0][0]             \n",
      "                                                                 bidirectional_decoder_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "combine_outputs (CombineOutputs (None, 5, 8, 250)    0           similarity_layer_choice_1[0][0]  \n",
      "                                                                 similarity_layer_choice_2[0][0]  \n",
      "                                                                 similarity_layer_choice_3[0][0]  \n",
      "                                                                 similarity_layer_choice_4[0][0]  \n",
      "                                                                 similarity_layer_choice_5[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 5, 8, 150)    37650       combine_outputs[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 5, 8, 150)    0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5, 8, 70)     10570       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5, 8, 70)     0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2800)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 5)            14005       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,239,131\n",
      "Trainable params: 4,239,131\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "bidaf_model = BidirectionalAttentionFlow(emdim=350, max_passage_length=None,\n",
    "                                             max_query_length=None,\n",
    "                                             num_highway_layers=2, num_decoders=2,\n",
    "                                             encoder_dropout=0.5, decoder_dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ks4qSUaKffQ"
   },
   "outputs": [],
   "source": [
    "bidaf_model.model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidaf_model.load_bidaf('saved_items/weights-improvement.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8zqtiyvFKffa"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data_generators(batch_size, emdim, squad_version=1.1, max_passage_length=None, max_query_length=None,\n",
    "                         shuffle=False):\n",
    "    train_generator = BatchGenerator('train', batch_size, emdim, squad_version, max_passage_length, max_query_length,\n",
    "                                     shuffle)\n",
    "    validation_generator = BatchGenerator('dev', batch_size, emdim, squad_version, max_passage_length, max_query_length,\n",
    "                                          shuffle)\n",
    "    return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-27YK_zCsj2"
   },
   "outputs": [],
   "source": [
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qb8mNqcqKffn"
   },
   "outputs": [],
   "source": [
    "'''BatchGenerator use to generate the batch of inputes contex with 250 words and query with 35 words and choice with 8 words\n",
    "i also used all the Easy and Challenge both combained data for train and validate '''\n",
    "\n",
    "from keras.utils import Sequence\n",
    "\n",
    "\n",
    "\n",
    "class BatchGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "\n",
    "    vectors = None\n",
    "\n",
    "    def __init__(self, gen_type, batch_size, emdim, squad_version, max_passage_length, max_query_length, shuffle):\n",
    "        'Initialization'\n",
    "\n",
    "        base_dir = \"storage/\"\n",
    "\n",
    "        self.vectors = MagnitudeVectors(emdim).load_vectors()\n",
    "        self.squad_version = squad_version\n",
    "\n",
    "        self.max_passage_length = max_passage_length\n",
    "        self.max_query_length = max_query_length\n",
    "\n",
    "        self.context_file = os.path.join(base_dir,'all_data', gen_type + '-v{}.cha_context'.format(squad_version))\n",
    "        self.question_file = os.path.join(base_dir,'all_data', gen_type + '-v{}.cha_question'.format(squad_version))\n",
    "        self.span_file_ans = os.path.join(base_dir,'all_data', gen_type + '-v{}.cha_choices'.format(squad_version))\n",
    "        self.span_file = os.path.join(base_dir,'all_data', gen_type + '-v{}.cha_answer'.format(squad_version))\n",
    "        \n",
    "        self.gen_type = gen_type\n",
    "        self.batch_size = batch_size\n",
    "        i = 0\n",
    "        with open(self.span_file, 'r', encoding='utf-8') as f:\n",
    "\n",
    "            for i, _ in enumerate(f):\n",
    "                pass\n",
    "        self.num_of_batches = (i + 1) // self.batch_size\n",
    "        self.indices = np.arange(i + 1)\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.num_of_batches\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        start_index = (index * self.batch_size) + 1\n",
    "        end_index = ((index + 1) * self.batch_size) + 1\n",
    "\n",
    "        inds = self.indices[start_index:end_index]\n",
    "\n",
    "        contexts = []\n",
    "        with open(self.context_file, 'r', encoding='utf-8') as cf:\n",
    "            for i, line in enumerate(cf, start=1):\n",
    "                line = line[:-1]\n",
    "                if i in inds:\n",
    "                    word_no=[]\n",
    "                    count=0\n",
    "                    for word in line.split(' '):\n",
    "                        if word.lower() not in stopwords and count<250 and word.strip() !='':\n",
    "                            count=count+1\n",
    "                            word_no.append(word.lower().strip())\n",
    "                    if count<250:\n",
    "                        for i in range(250 - count):\n",
    "                            word_no.append(0)    \n",
    "                    contexts.append(word_no)\n",
    "\n",
    "        questions = []\n",
    "        with open(self.question_file, 'r', encoding='utf-8') as qf:\n",
    "            for i, line in enumerate(qf, start=1):\n",
    "                line = line[:-1]\n",
    "                if i in inds:\n",
    "                    word_no=[]\n",
    "                    count=0\n",
    "                    for word in line.split(' '):\n",
    "                        #for i in word.split(','):\n",
    "                        if word.lower().strip() not in stopwords and count<35 and word.strip() !='':\n",
    "                            count=count+1\n",
    "                            word_no.append(word.lower().strip())\n",
    "                    if count<35:\n",
    "                        for i in range(35 - count):\n",
    "                            word_no.append(0)    \n",
    "                    questions.append(word_no)\n",
    "\n",
    "        answer_spans = []\n",
    "        with open(self.span_file, 'r', encoding='utf-8') as sf:\n",
    "            for i, line in enumerate(sf, start=1):\n",
    "                line = line[:-1]\n",
    "                if i in inds:\n",
    "                        line=line.strip()\n",
    "                        if line=='A' or line=='1':\n",
    "                            answer_spans.append([1,0,0,0,0])\n",
    "                        if line=='B' or line=='2':\n",
    "                            answer_spans.append([0,1,0,0,0])\n",
    "                        if line=='C' or line=='3':\n",
    "                            answer_spans.append([0,0,1,0,0])\n",
    "                        if line=='D' or line=='4':\n",
    "                            answer_spans.append([0,0,0,1,0])\n",
    "                        if line=='E':\n",
    "                            answer_spans.append([0,0,0,0,1])\n",
    "\n",
    "\n",
    "\n",
    "        answer_contexts = []\n",
    "        answer_choice_1=[]\n",
    "        answer_choice_2=[]\n",
    "        answer_choice_3=[]\n",
    "        answer_choice_4=[]\n",
    "        answer_choice_5=[]\n",
    "        \n",
    "        with open(self.span_file_ans, 'r', encoding='utf-8') as sf:\n",
    "            for i, line in enumerate(sf, start=1):\n",
    "                line = line[:-1]\n",
    "                if i in inds:\n",
    "                    word_no2=[]\n",
    "                    last_count=0\n",
    "                    for word in line.split(','):\n",
    "                        count=0\n",
    "                        word_no=[]\n",
    "                        for i in word.split(' '):\n",
    "                              if count<8 and i.strip() !='':\n",
    "                                    count=count+1\n",
    "                                    word_no.append(i.lower().strip())\n",
    "                    \n",
    "                        if count<8:\n",
    "                              for i in range(8 - count):\n",
    "                                      word_no.append(0)  \n",
    "                        word_no2.append(word_no)\n",
    "                        last_count=last_count+1\n",
    "                    if  last_count<5:\n",
    "                        last_count=last_count+1\n",
    "                        last_word_no=[]\n",
    "                        for i in range(8):\n",
    "                              last_word_no.append(0)\n",
    "                        word_no2.append(last_word_no)\n",
    "\n",
    "                    if  last_count<5:\n",
    "                        last_count=last_count+1\n",
    "                        last_word_no=[]\n",
    "                        for i in range(8):\n",
    "                              last_word_no.append(0)\n",
    "                        word_no2.append(last_word_no)\n",
    "                        \n",
    "                    answer_choice_1.append(word_no2[0])\n",
    "                    answer_choice_2.append(word_no2[1])\n",
    "                    answer_choice_3.append(word_no2[2])\n",
    "                    answer_choice_4.append(word_no2[3])\n",
    "                    answer_choice_5.append(word_no2[4])\n",
    "\n",
    "                    #answer_contexts.append(self.vectors.query(word_no2, pad_to_length=350))\n",
    "                   \n",
    "\n",
    "        context_batch = self.vectors.query(contexts, pad_to_length=self.max_passage_length)\n",
    "        question_batch = self.vectors.query(questions, pad_to_length=self.max_query_length)\n",
    "        #answer_contexts_batch = np.array(answer_contexts)\n",
    "        \n",
    "        answer_contexts_batch_1 = self.vectors.query(answer_choice_1, pad_to_length=self.max_query_length)\n",
    "        answer_contexts_batch_2 = self.vectors.query(answer_choice_2, pad_to_length=self.max_query_length)\n",
    "        answer_contexts_batch_3 = self.vectors.query(answer_choice_3, pad_to_length=self.max_query_length)\n",
    "        answer_contexts_batch_4 = self.vectors.query(answer_choice_4, pad_to_length=self.max_query_length)\n",
    "        answer_contexts_batch_5 = self.vectors.query(answer_choice_5, pad_to_length=self.max_query_length)\n",
    "        \n",
    "        return [context_batch, question_batch,answer_contexts_batch_1,answer_contexts_batch_2,answer_contexts_batch_3,answer_contexts_batch_4,answer_contexts_batch_5], [answer_spans]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "xdaG24cNKffu",
    "outputId": "546528c9-908f-4cd6-9b2c-54f29998aa3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will download magnitude files from the server if they aren't avaialble locally.. So, grab a cup of coffee while the downloading is under progress..\n",
      "Will download magnitude files from the server if they aren't avaialble locally.. So, grab a cup of coffee while the downloading is under progress..\n",
      "Epoch 1/20\n",
      "224/224 [==============================] - 1037s 5s/step - loss: 1.4712 - accuracy: 0.2699 - val_loss: 1.3882 - val_accuracy: 0.2503\n",
      "\n",
      "Epoch 00001: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 2/20\n",
      "224/224 [==============================] - 864s 4s/step - loss: 1.4308 - accuracy: 0.2429 - val_loss: 1.4182 - val_accuracy: 0.2573\n",
      "\n",
      "Epoch 00002: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 3/20\n",
      "224/224 [==============================] - 864s 4s/step - loss: 1.4245 - accuracy: 0.2521 - val_loss: 1.3844 - val_accuracy: 0.2573\n",
      "\n",
      "Epoch 00003: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 4/20\n",
      "224/224 [==============================] - 865s 4s/step - loss: 1.4217 - accuracy: 0.2592 - val_loss: 1.3968 - val_accuracy: 0.2643\n",
      "\n",
      "Epoch 00004: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 5/20\n",
      "224/224 [==============================] - 875s 4s/step - loss: 1.4147 - accuracy: 0.2497 - val_loss: 1.4677 - val_accuracy: 0.2620\n",
      "\n",
      "Epoch 00005: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 6/20\n",
      "224/224 [==============================] - 870s 4s/step - loss: 1.4032 - accuracy: 0.2515 - val_loss: 1.3816 - val_accuracy: 0.2573\n",
      "\n",
      "Epoch 00006: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 7/20\n",
      "224/224 [==============================] - 868s 4s/step - loss: 1.4089 - accuracy: 0.2521 - val_loss: 1.3669 - val_accuracy: 0.2608\n",
      "\n",
      "Epoch 00007: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 8/20\n",
      "224/224 [==============================] - 865s 4s/step - loss: 1.4154 - accuracy: 0.2342 - val_loss: 1.3683 - val_accuracy: 0.2608\n",
      "\n",
      "Epoch 00008: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 9/20\n",
      "224/224 [==============================] - 864s 4s/step - loss: 1.4040 - accuracy: 0.2432 - val_loss: 1.3615 - val_accuracy: 0.2480\n",
      "\n",
      "Epoch 00009: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 10/20\n",
      "224/224 [==============================] - 871s 4s/step - loss: 1.4118 - accuracy: 0.2500 - val_loss: 1.3717 - val_accuracy: 0.2596\n",
      "\n",
      "Epoch 00010: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 11/20\n",
      "224/224 [==============================] - 883s 4s/step - loss: 1.4043 - accuracy: 0.2515 - val_loss: 1.3649 - val_accuracy: 0.2561\n",
      "\n",
      "Epoch 00011: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 12/20\n",
      "224/224 [==============================] - 867s 4s/step - loss: 1.4076 - accuracy: 0.2539 - val_loss: 1.3747 - val_accuracy: 0.2596\n",
      "\n",
      "Epoch 00012: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 13/20\n",
      "224/224 [==============================] - 870s 4s/step - loss: 1.4038 - accuracy: 0.2747 - val_loss: 1.3779 - val_accuracy: 0.2596\n",
      "\n",
      "Epoch 00013: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 14/20\n",
      "224/224 [==============================] - 870s 4s/step - loss: 1.4053 - accuracy: 0.2539 - val_loss: 1.3755 - val_accuracy: 0.2573\n",
      "\n",
      "Epoch 00014: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 15/20\n",
      "224/224 [==============================] - 867s 4s/step - loss: 1.4170 - accuracy: 0.2565 - val_loss: 1.3775 - val_accuracy: 0.2620\n",
      "\n",
      "Epoch 00015: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 16/20\n",
      "224/224 [==============================] - 878s 4s/step - loss: 1.3926 - accuracy: 0.2500 - val_loss: 1.3820 - val_accuracy: 0.2702\n",
      "\n",
      "Epoch 00016: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 17/20\n",
      "224/224 [==============================] - 868s 4s/step - loss: 1.4191 - accuracy: 0.2574 - val_loss: 1.4148 - val_accuracy: 0.2608\n",
      "\n",
      "Epoch 00017: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 18/20\n",
      "224/224 [==============================] - 866s 4s/step - loss: 1.4063 - accuracy: 0.2610 - val_loss: 1.4077 - val_accuracy: 0.2608\n",
      "\n",
      "Epoch 00018: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 19/20\n",
      "224/224 [==============================] - 864s 4s/step - loss: 1.4041 - accuracy: 0.2607 - val_loss: 1.3597 - val_accuracy: 0.2643\n",
      "\n",
      "Epoch 00019: saving model to saved_items/weights-improvement.hdf5\n",
      "Epoch 20/20\n",
      "224/224 [==============================] - 866s 4s/step - loss: 1.3992 - accuracy: 0.2530 - val_loss: 1.3404 - val_accuracy: 0.2573\n",
      "\n",
      "Epoch 00020: saving model to saved_items/weights-improvement.hdf5\n",
      "Training Completed!\n"
     ]
    }
   ],
   "source": [
    "'''Generate the batch and train the model with batch 15 and epoch 20'''\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "import warnings \n",
    "from time import time\n",
    "\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_generator, validation_generator = load_data_generators(batch_size=15, emdim=350,\n",
    "                                                                     squad_version=1.1,\n",
    "                                                                     max_passage_length=None,\n",
    "                                                                     max_query_length=None,\n",
    "                                                                     shuffle=False)\n",
    "\n",
    "bidaf_model.train_model(train_generator, steps_per_epoch=None, epochs=20,\n",
    "                                validation_generator=validation_generator, validation_steps=None, use_multiprocessing=False,\n",
    "                                shuffle=False, save_history=False,\n",
    "                                save_model_per_epoch=True)\n",
    "\n",
    "print(\"Training Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvAblg_R2arA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data_generators_test(batch_size, emdim, squad_version=1.1, max_passage_length=None, max_query_length=None,\n",
    "                         shuffle=False):\n",
    "    test_generator = BatchGenerator('test', batch_size, emdim, squad_version, max_passage_length, max_query_length,\n",
    "                                     shuffle)\n",
    "    \n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "4xidHgPpKff2",
    "outputId": "4a475d1c-2c9b-4dba-dc2c-4d337d3c905a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will download magnitude files from the server if they aren't avaialble locally.. So, grab a cup of coffee while the downloading is under progress..\n"
     ]
    }
   ],
   "source": [
    "'''I have used only the Challenge data for testing '''\n",
    "\n",
    "test_generator = load_data_generators_test(batch_size=15, emdim=350,\n",
    "                                                                     squad_version=1.1,\n",
    "                                                                     max_passage_length=None,\n",
    "                                                                     max_query_length=None,\n",
    "                                                                     shuffle=False)\n",
    "\n",
    "loss,acc = bidaf_model.model.evaluate(test_generator, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "-4IPP_gYAjdR",
    "outputId": "6ce4af15-150b-4598-ac25-f874c7384012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.2777777910232544  Test Loss:  1.484659194946289\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: \",acc,\" Test Loss: \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Leader board The BiDAF model has accuracy of 26.54 %  here i have improved the model as 27.77 %\n",
    "\n",
    "https://leaderboard.allenai.org/arc/submissions/public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure case:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) While sending the context words more than 300 the model is not improving the loss \n",
    "\n",
    "2) Mode Over fit while batch size is 5,10\n",
    "\n",
    "3) if the padding is more in contex,query the model not improving the loss\n",
    "\n",
    "4) sending the choices at single string and calculating the similarity also go to over fitting of model \n",
    "\n",
    "5) sending the choices with question also not improving the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Case_Study_BiDaf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
