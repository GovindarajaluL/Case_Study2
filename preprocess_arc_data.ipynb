{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##                     ThinkyouhaveSolvedQuestionAnswering?              TryARC,theAI2ReasoningChallenge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ARC dataset contains 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in advanced question-answering. The dataset is partitioned into a Challenge Set and an Easy Set, where the former contains only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm\n",
    "\n",
    "Problem Statement :\n",
    "                Need to solve the Question Answering based on the ARC Corpus given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Probelm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1)This data set consists of 7,787 science exam questions\n",
    "    2)The questions are sorted into a Challenge Set of 2,590 “hard” questions and an Easy Set of 5,197 questions\n",
    "    3)Each set is provided in two formats, CSV and JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSONL Structure:\n",
    "\n",
    "            The JSONL files contain the same questions split into the “stem” of the question (the question text) and then the various answer “choices” and their corresponding labels (A, B, C, D). The questionID is also included.\n",
    "            \n",
    "            \n",
    "            {\"id\":\"MCAS_2000_4_6\",\"question\":{\"stem\":\"Which technology was developed most recently?\",\"choices\":[{\"text\":\"cellular telephone\",\"label\":\"A\"},{\"text\":\"television\",\"label\":\"B\"},{\"text\":\"refrigerator\",\"label\":\"C\"},{\"text\":\"airplane\",\"label\":\"D\"}]},\"answerKey\":\"A\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    id - a unique identifier for the question (our own numbering)\n",
    "    question\n",
    "        stem - the question text\n",
    "        choices - the answer choices\n",
    "            label - the answer label (\"A\", \"B\", \"C\", \"D\")\n",
    "                text - the text associated with the answer label\n",
    "        answerKey - the the correct answer option\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Comma-delimited (CSV) columns:\n",
    "\n",
    "        questionID - a unique identifier for the question (our own numbering)\n",
    "        originalQuestionID - the question number on the test\n",
    "        totalPossiblePoint - how many points the question is worth when scoring\n",
    "        AnswerKey - the correct answer option\n",
    "        isMultipleChoiceQuestion - 1 = multiple choice, 0 = other\n",
    "        includesDiagram - 1 = includes diagram, 0 = other\n",
    "        examName - the source of the exam\n",
    "        schoolGrade - grade level\n",
    "        year - publication year of the exam\n",
    "        question - the text of the question itself\n",
    "        subject - the general question topic\n",
    "        category - Test, Train, or Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Example Data point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mercury_7057260,7057260,1,C,1,0,Mercury,8,2015,A student hypothesizes that algae are producers. Which question will best help the student determine if this is correct? (A) Do algae consume other organisms? (B) Which organisms consume algae? (C) Do algae use sunlight to make food? (D) Could an ecosystem survive without algae?,,Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACTAAP_2014_7_6,6,1,A,1,0,ACTAAP,7,2014,Soccer players use their muscle systems to kick a ball into a goal. What organ system coordinates the muscles? (A) The nervous system (B) The endocrine system (C) The respiratory system (D) The circulatory system,,Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Train , CV and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Challenge Train: 1,119\n",
    "    Challenge Dev: 299\n",
    "    Challenge Test: 1,172\n",
    "\n",
    "    Easy Train: 2,251\n",
    "    Easy Dev: 570\n",
    "    Easy Test: 2,376"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Data Corpus\n",
    "    The ARC Corpus, containing 14M science-related sentences with knowledge relevantto ARC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.5 Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Perform any of the neural model to cross the score of 67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import check_output\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import distance\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Reading data and basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 1119\n"
     ]
    }
   ],
   "source": [
    "Challenge_Train_df = pd.read_csv(\"ARC-V1-Feb2018-2/ARC-Challenge/ARC-Challenge-Train.csv\")\n",
    "\n",
    "print(\"Number of data points:\",Challenge_Train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionID</th>\n",
       "      <th>originalQuestionID</th>\n",
       "      <th>totalPossiblePoint</th>\n",
       "      <th>AnswerKey</th>\n",
       "      <th>isMultipleChoiceQuestion</th>\n",
       "      <th>includesDiagram</th>\n",
       "      <th>examName</th>\n",
       "      <th>schoolGrade</th>\n",
       "      <th>year</th>\n",
       "      <th>question</th>\n",
       "      <th>subject</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mercury_SC_415702</td>\n",
       "      <td>415702</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>3</td>\n",
       "      <td>2015</td>\n",
       "      <td>George wants to warm his hands quickly by rubb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCAS_2009_5_6516</td>\n",
       "      <td>6516</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MCAS</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>Which of the following statements best explain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mercury_7233695</td>\n",
       "      <td>7233695</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>A fold observed in layers of sedimentary rock ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mercury_7041615</td>\n",
       "      <td>7041615</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>Which of these do scientists offer as the most...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mercury_7041860</td>\n",
       "      <td>7041860</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>A boat is acted on by a river current flowing ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          questionID originalQuestionID  totalPossiblePoint AnswerKey  \\\n",
       "0  Mercury_SC_415702             415702                   1         A   \n",
       "1   MCAS_2009_5_6516               6516                   1         B   \n",
       "2    Mercury_7233695            7233695                   1         B   \n",
       "3    Mercury_7041615            7041615                   1         D   \n",
       "4    Mercury_7041860            7041860                   1         B   \n",
       "\n",
       "   isMultipleChoiceQuestion  includesDiagram examName  schoolGrade  year  \\\n",
       "0                         1                0  Mercury            3  2015   \n",
       "1                         1                0     MCAS            5  2009   \n",
       "2                         1                0  Mercury            9  2015   \n",
       "3                         1                0  Mercury            8  2015   \n",
       "4                         1                0  Mercury            8  2015   \n",
       "\n",
       "                                            question  subject category  \n",
       "0  George wants to warm his hands quickly by rubb...      NaN    Train  \n",
       "1  Which of the following statements best explain...      NaN    Train  \n",
       "2  A fold observed in layers of sedimentary rock ...      NaN    Train  \n",
       "3  Which of these do scientists offer as the most...      NaN    Train  \n",
       "4  A boat is acted on by a river current flowing ...      NaN    Train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Challenge_Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1119 entries, 0 to 1118\n",
      "Data columns (total 12 columns):\n",
      "questionID                  1119 non-null object\n",
      "originalQuestionID          1119 non-null object\n",
      "totalPossiblePoint          1119 non-null int64\n",
      "AnswerKey                   1119 non-null object\n",
      "isMultipleChoiceQuestion    1119 non-null int64\n",
      "includesDiagram             1119 non-null int64\n",
      "examName                    1119 non-null object\n",
      "schoolGrade                 1119 non-null int64\n",
      "year                        1119 non-null object\n",
      "question                    1119 non-null object\n",
      "subject                     0 non-null float64\n",
      "category                    1119 non-null object\n",
      "dtypes: float64(1), int64(4), object(7)\n",
      "memory usage: 105.0+ KB\n"
     ]
    }
   ],
   "source": [
    "Challenge_Train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "    1)There are 12 columns and 1119 rows\n",
    "    2)The subject column contains no value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Distribution of data points among output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e67fc16fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Challenge_Train_df.groupby(\"AnswerKey\")['questionID'].count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerKey\n",
       "1      6\n",
       "2      3\n",
       "3      4\n",
       "4     10\n",
       "A    233\n",
       "B    293\n",
       "C    287\n",
       "D    283\n",
       "Name: questionID, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Challenge_Train_df.groupby(\"AnswerKey\")['questionID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "    1)Most of the question answers are A,B,C,D\n",
    "    2)There are some question with answers are 1,2,3,4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows based on 2 columns are:\n",
      "Empty DataFrame\n",
      "Columns: [questionID, originalQuestionID, totalPossiblePoint, AnswerKey, isMultipleChoiceQuestion, includesDiagram, examName, schoolGrade, year, question, subject, category]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select all duplicate rows based on multiple column names in list\n",
    "duplicateRowsDF = Challenge_Train_df[Challenge_Train_df.duplicated(['questionID','question'])]\n",
    "print(\"Duplicate Rows based on 2 columns are:\", duplicateRowsDF, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "    There is no dublicate question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 Checking School Grade Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schoolGrade\n",
       "3     47\n",
       "4    105\n",
       "5    210\n",
       "6     27\n",
       "7    175\n",
       "8    456\n",
       "9     99\n",
       "Name: questionID, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Challenge_Train_df.groupby(\"schoolGrade\")['questionID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "    1) Questions for grade 8 is high 456\n",
    "    2) Questions for grade 6 is low 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.4 Checking MultiChoice Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isMultipleChoiceQuestion\n",
       "1    1119\n",
       "Name: questionID, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Challenge_Train_df.groupby(\"isMultipleChoiceQuestion\")['questionID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "    Every question has only 1 answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.4 Checking Exam Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "examName\n",
       "ACTAAP                                                   39\n",
       "AIMS                                                      6\n",
       "Alaska Department of Education & Early Development        7\n",
       "Alaska Department of Education and Early Development      6\n",
       "Alaska Dept. of Education & Early Development             8\n",
       "California Standards Test                                 5\n",
       "California Standards Test - Science                       8\n",
       "FCAT                                                      1\n",
       "Louisiana Educational Assessment Program                 14\n",
       "MCAS                                                     97\n",
       "MEA                                                      16\n",
       "MEAP                                                      6\n",
       "MSA                                                      14\n",
       "Maryland School Assessment                               13\n",
       "Maryland School Assessment - Science                     19\n",
       "Mercury                                                 736\n",
       "NAEP                                                      4\n",
       "NYSEDREGENTS                                             42\n",
       "North Carolina READY End-of-Grade Assessment             26\n",
       "Ohio Achievement Tests                                    3\n",
       "TAKS                                                      4\n",
       "TIMSS                                                    25\n",
       "Virginia Standards of Learning - Science                 19\n",
       "WASL                                                      1\n",
       "Name: questionID, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Challenge_Train_df.groupby(\"examName\")['questionID'].count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1)Mercury exams has high Questions\n",
    "    2)WASL & FCAT exams has low  Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_from_json(filename):\n",
    "    \"\"\"Loads JSON data from filename and returns\"\"\"\n",
    "    dataset=[]\n",
    "    i=0\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "            for l in f.readlines():\n",
    "                ll = json.loads(l.strip())\n",
    "                dataset.append(ll)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_to_file(out_file, line):\n",
    "    \"\"\"Take a line and file as input, encdes the line to utf-8 and then writes that line to the file\"\"\"\n",
    "    out_file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sequence, do_lowercase):\n",
    "    \"\"\"Tokenizes the input sequence using nltk's word_tokenize function, replaces two single quotes with a double quote\"\"\"\n",
    "\n",
    "    tokens = [token.replace(\"``\", '\"').replace(\"''\", '\"').lower() for token in nltk.word_tokenize(sequence)]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the text corpus and loading it into context.txt\n",
    "context_tokens=[]\n",
    "charloc2wordloc=dict()\n",
    "examples=[]\n",
    "filepath = 'D:\\Ai_Course_Doc\\case_1\\dataset\\ARC_Corpus.txt'\n",
    "filewritepath = 'D:\\Ai_Course_Doc\\case_1\\dataset\\context.txt'\n",
    "\n",
    "with open(filepath,'r', encoding=\"utf8\") as fp:\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        # use realine() to read next line\n",
    "        line = fp.readline()\n",
    "        context=line\n",
    "        context = context.replace(\"''\", '\" ')\n",
    "        context = context.replace(\"``\", '\" ')\n",
    "        context_tokens = tokenize(context, False )  # list of strings (lowercase)\n",
    "        examples.append(' '.join(context_tokens))\n",
    "        break\n",
    "fp.close()\n",
    "\n",
    "with open(filewritepath, 'w', encoding='utf-8') as context_file:\n",
    "    for tokens in examples:\n",
    "        write_to_file(context_file, tokens)\n",
    "    context_file.close()\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the  question,answer and choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the question,answer and choices and loading it into as file \n",
    "\n",
    "question_tokens=[]\n",
    "ans_tokens=[]\n",
    "choices_tokens=[]\n",
    "ans_word_tokens=[]\n",
    "\n",
    "def preprocess_and_write(dataset, tier):\n",
    "    tt=0\n",
    "    squad_version=1.1\n",
    "    out_dir =\"D:\\Ai_Course_Doc\\case_1\\dataset\"\n",
    "    for qn in dataset:\n",
    "\n",
    "    # read the question text and tokenize\n",
    "        question = qn['question']['stem'] # string\n",
    "        question_tokens.append(tokenize(question, True))\n",
    "\n",
    "        text_list=\"\"\n",
    "        ans_text=\"\"\n",
    "        for ans in qn['question']['choices']: \n",
    "          \n",
    "            text_list+=str(tokenize(ans['text'],True))+str(' ')\n",
    "            if ans['label']==qn['answerKey']:\n",
    "                ans_text=ans['text']\n",
    "\n",
    "        ans_tokens.append(qn['answerKey'])\n",
    "        ans_word_tokens.append(ans_text)\n",
    "        choices_tokens.append(text_list)\n",
    "        \n",
    "    with open(os.path.join(out_dir, tier + '-v{}.cha_question'.format(squad_version)), 'w', encoding='utf-8') as question_file,\\\n",
    "        open(os.path.join(out_dir, tier + '-v{}.cha_choices'.format(squad_version)), 'w', encoding='utf-8') as choices_file,\\\n",
    "        open(os.path.join(out_dir, tier + '-v{}.cha_answer'.format(squad_version)), 'w', encoding='utf-8') as ans_text_file,\\\n",
    "        open(os.path.join(out_dir, tier + '-v{}.cha_word_answer'.format(squad_version)), 'w', encoding='utf-8') as ans_word_text_file:\n",
    "        \n",
    "        for i in range(len(question_tokens)):\n",
    "            write_to_file(question_file, str(question_tokens[i]))\n",
    "            write_to_file(ans_text_file, str(ans_tokens[i]))\n",
    "            write_to_file(choices_file, str(choices_tokens[i]))\n",
    "            write_to_file(ans_word_text_file, str(ans_word_tokens[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_dir =\"D:\\Ai_Course_Doc\\case_1\\ARC-V1-Feb2018-2\\ARC-Challenge\"\n",
    "\n",
    "squad_version=1.1\n",
    "\n",
    "train_filename = \"ARC-Challenge-Train.jsonl\".format(squad_version)\n",
    "\n",
    "train_data = data_from_json(os.path.join(data_dir, train_filename))\n",
    "\n",
    "preprocess_and_write(train_data, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_SC_415702',\n",
       " 'question': {'stem': 'George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most heat?',\n",
       "  'choices': [{'text': 'dry palms', 'label': 'A'},\n",
       "   {'text': 'wet palms', 'label': 'B'},\n",
       "   {'text': 'palms covered with oil', 'label': 'C'},\n",
       "   {'text': 'palms covered with lotion', 'label': 'D'}]},\n",
       " 'answerKey': 'A'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_dir =\"D:\\Ai_Course_Doc\\case_1\\ARC-V1-Feb2018-2\\ARC-Challenge\"\n",
    "\n",
    "squad_version=1.1\n",
    "\n",
    "dev_filename = \"ARC-Challenge-Dev.jsonl\".format(squad_version)\n",
    "\n",
    "dev_data = data_from_json(os.path.join(data_dir, dev_filename))\n",
    "\n",
    "preprocess_and_write(dev_data, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir =\"D:\\Ai_Course_Doc\\case_1\\ARC-V1-Feb2018-2\\ARC-Challenge\"\n",
    "\n",
    "squad_version=1.1\n",
    "\n",
    "test_filename = \"ARC-Challenge-Test.jsonl\".format(squad_version)\n",
    "\n",
    "test_data = data_from_json(os.path.join(data_dir, test_filename))\n",
    "\n",
    "preprocess_and_write(test_data, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1172"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the intrection words between the Question and Context  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contex_data = pd.read_csv('D:\\Ai_Course_Doc\\case_1\\dataset\\context.txt', header = None,delimiter= '\\n',names=[\"contex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paleoceanography 8 2 193 208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of course for many in the media hydrogen sulph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The same problems apply with wolf domestic dog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taking stock of delightful days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The an tlu opologist and the ethnologist find ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              contex\n",
       "0                       Paleoceanography 8 2 193 208\n",
       "1  Of course for many in the media hydrogen sulph...\n",
       "2  The same problems apply with wolf domestic dog...\n",
       "3                    taking stock of delightful days\n",
       "4  The an tlu opologist and the ethnologist find ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contex_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The intersection words between the question and context line should be minimum 3\n",
    "\n",
    "contex_line=[]\n",
    "data_dir =\"/content/drive/My Drive/case_study_1\"\n",
    "out_dir =\"/content/drive/My Drive/case_study_1/ch_files\"\n",
    "\n",
    "squad_version=1.1\n",
    "\n",
    "train_filename = \"ARC-Challenge-Train.jsonl\".format(squad_version)\n",
    "\n",
    "train_data = data_from_json(os.path.join(data_dir, train_filename))\n",
    "i=0\n",
    "with open(os.path.join(out_dir, 'train' + '-v{}.cha_context'.format(squad_version)), 'w', encoding='utf-8') as context_file:\n",
    "    for qn in train_data:\n",
    "        \n",
    "\n",
    "        # read the question text and tokenize\n",
    "        question = qn['question']['stem'] # string\n",
    "        document_1_words=[word for word in tokenize(question, True) if not word in stop_words]\n",
    "        document_1_words=[re.sub('[^a-zA-Z0-9]+','govind' , _) for _ in document_1_words]\n",
    "        text_list=\"\"\n",
    "        for line in contex_data[\"contex\"]:\n",
    "            document_2_words = line.split() \n",
    "            common = set(document_1_words).intersection( set(document_2_words) )\n",
    "\n",
    "            if(len(common)>3):\n",
    "                text_list+=line+str(' ')\n",
    "                \n",
    "        if text_list.strip()==\"\":\n",
    "            for line in contex_data[\"contex\"]:\n",
    "                document_2_words = line.split() \n",
    "                common = set(document_1_words).intersection( set(document_2_words) )\n",
    "\n",
    "                if(len(common)>2):\n",
    "                    text_list+=line+str(' ')\n",
    "            \n",
    "\n",
    "        write_to_file(context_file,text_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The intersection words between the question and context line should be minimum 3\n",
    "\n",
    "contex_line=[]\n",
    "data_dir =\"/content/drive/My Drive/case_study_1\"\n",
    "out_dir =\"/content/drive/My Drive/case_study_1/ch_files\"\n",
    "\n",
    "squad_version=1.1\n",
    "\n",
    "train_filename = \"ARC-Challenge-Dev.jsonl\".format(squad_version)\n",
    "\n",
    "train_data = data_from_json(os.path.join(data_dir, train_filename))\n",
    "i=0\n",
    "with open(os.path.join(out_dir, 'dev' + '-v{}.cha_context'.format(squad_version)), 'w', encoding='utf-8') as context_file:\n",
    "    for qn in train_data:\n",
    "        \n",
    "\n",
    "        # read the question text and tokenize\n",
    "        question = qn['question']['stem'] # string\n",
    "        document_1_words=[word for word in tokenize(question, True) if not word in stop_words]\n",
    "        document_1_words=[re.sub('[^a-zA-Z0-9]+','govind' , _) for _ in document_1_words]\n",
    "        text_list=\"\"\n",
    "        for line in contex_data[\"contex\"]:\n",
    "            document_2_words = line.split() \n",
    "            common = set(document_1_words).intersection( set(document_2_words) )\n",
    "\n",
    "            if(len(common)>3):\n",
    "                text_list+=line+str(' ')\n",
    "                \n",
    "        if text_list.strip()==\"\":\n",
    "            for line in contex_data[\"contex\"]:\n",
    "                document_2_words = line.split() \n",
    "                common = set(document_1_words).intersection( set(document_2_words) )\n",
    "\n",
    "                if(len(common)>2):\n",
    "                    text_list+=line+str(' ')\n",
    "            \n",
    "\n",
    "        write_to_file(context_file,text_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The intersection words between the question and context line should be minimum 3\n",
    "\n",
    "contex_line=[]\n",
    "data_dir =\"/content/drive/My Drive/case_study_1\"\n",
    "out_dir =\"/content/drive/My Drive/case_study_1/ch_files\"\n",
    "\n",
    "squad_version=1.1\n",
    "\n",
    "train_filename = \"ARC-Challenge-Test.jsonl\".format(squad_version)\n",
    "\n",
    "train_data = data_from_json(os.path.join(data_dir, train_filename))\n",
    "i=0\n",
    "with open(os.path.join(out_dir, 'test' + '-v{}.cha_context'.format(squad_version)), 'w', encoding='utf-8') as context_file:\n",
    "    for qn in train_data:\n",
    "        \n",
    "\n",
    "        # read the question text and tokenize\n",
    "        question = qn['question']['stem'] # string\n",
    "        document_1_words=[word for word in tokenize(question, True) if not word in stop_words]\n",
    "        document_1_words=[re.sub('[^a-zA-Z0-9]+',' ' , _) for _ in document_1_words]\n",
    "        text_list=\"\"\n",
    "        for line in contex_data[\"contex\"]:\n",
    "            document_2_words = line.split() \n",
    "            common = set(document_1_words).intersection( set(document_2_words) )\n",
    "\n",
    "            if(len(common)>3):\n",
    "                text_list+=line+str(' ')\n",
    "                \n",
    "        if text_list.strip()==\"\":\n",
    "            for line in contex_data[\"contex\"]:\n",
    "                document_2_words = line.split() \n",
    "                common = set(document_1_words).intersection( set(document_2_words) )\n",
    "\n",
    "                if(len(common)>2):\n",
    "                    text_list+=line+str(' ')\n",
    "            \n",
    "\n",
    "        write_to_file(context_file,text_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the matching between the answer and preprocessed context for each question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "contex_data=[]\n",
    "with open('D:/Ai_Course_Doc/case_1/drive-download-20200107T165248Z-001/ch_files/train-v1.1.cha_context', 'r', encoding='utf-8') as f:\n",
    "    for line in f.read().split(\"\\n\"):\n",
    "        contex_data.append(line)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1119"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_data=[]\n",
    "with open('D:/Ai_Course_Doc/case_1/dataset/train-v1.1.cha_word_answer', 'r', encoding='utf-8') as f:\n",
    "    for line in f.read().split(\"\\n\"):\n",
    "        answer_data.append(line.strip())\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1119"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_word=0\n",
    "con_word=0\n",
    "empty_contex=0\n",
    "for answer,contex in zip(answer_data,contex_data):\n",
    "    if len(contex) <3:\n",
    "        empty_contex=empty_contex+1\n",
    "    for contex_line in contex.split(','):\n",
    "        if answer in contex_line:\n",
    "            ans_word=ans_word+1\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer in given contex  9.363636363636363 %\n",
      "empty contex  3.5454545454545454 %\n"
     ]
    }
   ],
   "source": [
    "print('answer in given contex ',ans_word/len(answer),'%')\n",
    "print('empty contex ',empty_contex/len(answer),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation :\n",
    "\n",
    "1)There are 9.36% of exact answers are in the preprocesed row context in itself\n",
    "\n",
    "2)There are 3.54% of contex are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Randome model predict acc of  0.21894548704200179 %\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "Random_acc=0\n",
    "total_count=0\n",
    "with open('D:/Ai_Course_Doc/case_1/dataset/train-v1.1.cha_answer', 'r', encoding='utf-8') as sf:\n",
    "    for line in sf:\n",
    "        random_choice=random.choice(['A', 'B', 'C', 'D'])\n",
    "        line=line.strip()\n",
    "        if (line=='A' or line=='1') and random_choice=='A':\n",
    "            Random_acc=Random_acc+1\n",
    "        if (line=='B' or line=='2') and  random_choice=='B':\n",
    "            Random_acc=Random_acc+1\n",
    "        if (line=='C' or line=='3' ) and  random_choice=='C':\n",
    "            Random_acc=Random_acc+1\n",
    "        if (line=='D' or line=='4') and  random_choice=='D':\n",
    "            Random_acc=Random_acc+1\n",
    "        total_count=total_count+1\n",
    "\n",
    "print(\"The Randome model predict acc of \",Random_acc/total_count,\"%\"  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding for the Answerkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_one_hot=[]\n",
    "cout_A=0\n",
    "cout_B=0\n",
    "cout_C=0\n",
    "cout_D=0\n",
    "cout_E=0\n",
    "total=0\n",
    "for ans in Challenge_Train_df['AnswerKey'].values:\n",
    "    if ans=='A' or ans=='1':\n",
    "        ans_one_hot.append([1,0,0,0,0])\n",
    "        cout_A=cout_A+1\n",
    "    if ans=='B' or ans=='2':\n",
    "        ans_one_hot.append([0,1,0,0,0])\n",
    "        cout_B=cout_B+1\n",
    "    if ans=='C' or ans=='3':\n",
    "        ans_one_hot.append([0,0,1,0,0])\n",
    "        cout_C=cout_C+1\n",
    "    if ans=='D' or ans=='4':\n",
    "        ans_one_hot.append([0,0,0,1,0])\n",
    "        cout_D=cout_D+1\n",
    "    if ans=='E':\n",
    "        ans_one_hot.append([0,0,0,0,1])\n",
    "        cout_E=cout_E+1\n",
    "        \n",
    "    total=total+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_one_hot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = 0.21358355674709562\n",
      "B = 0.2645218945487042\n",
      "C = 0.26005361930294907\n",
      "D = 0.26184092940125114\n",
      "E = 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"A =\",cout_A/total)\n",
    "print(\"B =\",cout_B/total)\n",
    "print(\"C =\",cout_C/total)\n",
    "print(\"D =\",cout_D/total)\n",
    "print(\"E =\",cout_E/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = 0.24344735673034207\n",
      "B = 0.2612172367836517\n",
      "C = 0.2567747667703243\n",
      "D = 0.23767214571301643\n",
      "E = 0.000888494002665482\n"
     ]
    }
   ],
   "source": [
    "print(\"A =\",cout_A/total)\n",
    "print(\"B =\",cout_B/total)\n",
    "print(\"C =\",cout_C/total)\n",
    "print(\"D =\",cout_D/total)\n",
    "print(\"E =\",cout_E/total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=pd.DataFrame([ans_one_hot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(Challenge_Train_df['AnswerKey'].values),\n",
    "                                                 Challenge_Train_df['AnswerKey'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.3125    , 46.625     , 34.96875   , 13.9875    ,  0.60032189,\n",
       "        0.47738908,  0.48736934,  0.49425795])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_th=[]\n",
    "word_no=0\n",
    "k=0\n",
    "\n",
    "with open('D:/Ai_Course_Doc/case_1/drive-download-20200107T165248Z-001/ch_files/train-v1.1.cha_context', 'r', encoding='utf-8') as cf:\n",
    "    for line in cf:\n",
    "        word_no=0\n",
    "        for word in line.split(' '):\n",
    "            if word.lower() not in stopwords:\n",
    "                  word_no=word_no+1\n",
    "        len_th.append(word_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-> 0  value  1.0\n",
      "i-> 25  value  141.5\n",
      "i-> 50  value  604.0\n",
      "i-> 75  value  2247.5\n",
      "i-> 100  value  850181.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,25):\n",
    "    print('i->',i,' value ',np.percentile(len_th, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_th=[]\n",
    "word_no=0\n",
    "k=0\n",
    "\n",
    "with open('D:/Ai_Course_Doc/case_1/dataset/train-v1.1.cha_choices', 'r', encoding='utf-8') as cf:\n",
    "    for line in cf:\n",
    "        word_no=0\n",
    "        for word in line.split('] ['):\n",
    "            word=word.replace(\"'\",'').replace(\"[\",'').replace(\"]\",'')\n",
    "            for i in word.split(','):\n",
    "                    word_no=word_no+1\n",
    "        len_th.append(word_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-> 0  value  4.0\n",
      "i-> 25  value  8.0\n",
      "i-> 50  value  20.0\n",
      "i-> 75  value  31.0\n",
      "i-> 100  value  124.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,25):\n",
    "    print('i->',i,' value ',np.percentile(len_th, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_th=[]\n",
    "word_no=0\n",
    "k=0\n",
    "\n",
    "with open('D:/Ai_Course_Doc/case_1/dataset/train-v1.1.cha_question', 'r', encoding='utf-8') as cf:\n",
    "    for line in cf:\n",
    "        word_no=0\n",
    "        for word in line.split(','):\n",
    "              word=word.replace(\"'\",'').replace(\"?\",'')\n",
    "      #for i in word.split(','):\n",
    "              if word.lower() not in stopwords:\n",
    "                word_no=word_no+1\n",
    "        len_th.append(word_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-> 0  value  5.0\n",
      "i-> 25  value  12.0\n",
      "i-> 50  value  18.0\n",
      "i-> 75  value  29.0\n",
      "i-> 100  value  111.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,101,25):\n",
    "    print('i->',i,' value ',np.percentile(len_th, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
